{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zihvvan/MachineLearning/blob/main/zihvvan/CH08_07%2B08_%EB%B3%B5%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Xgboost\n",
        "\n",
        "* 결정 트리 (의사결정나무) : 특정한 변수를 기준으로 두 그룹으로 나눠서, 예측값을 맞추는 알고리즘\n",
        "    * 부분적인 데이터에 너무 특화되어서 과최적화 일어날 수 있다\n",
        "* (배깅-부트스트랩) : 부분적인 데이터 행을 가지고 무작위&복원추출 -> 부분집합 -> 과최적화\n",
        "* 랜덤 포레스트 : 데이터 행 + 데이터 열 -> 부분집합을 만들자\n",
        "(배깅, 랜덤 포레스트 -> 각 트리들이 독립적 -> 각각 만들어질 때 서로에게 영향X)\n",
        "---\n",
        "* 부스팅 : 각각의 이전에 만들어진 트리가 이후 만들어진 트리에 영향을 줘서, 좀 더 정확하게 & 더 빠르게 만들 수 있는 성능 개선 기법\n",
        "    * adaboost : 잘 분류 안되는 데이터들한테 가중치를 줘서 이걸 좀 더 집중적으로 분류할 수 있게...\n",
        "* 경사부스팅\n",
        "    * 경사하강법 -> 오류 -> 오류 함수, 손실 함수 -> 기울기를 최적화 방식으로 -> 오류를 줄이는 방식\n",
        "    * Xgboost, LightGBM, Catboost\n"
      ],
      "metadata": {
        "id": "WDmo6jVHEnpz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LightGBM\n",
        "* 리프 중심 트리 분할\n",
        "* 트리 - 루트(부모) 노드 -> 리프(자식) 노드 \n",
        "(<-> XGBoost : 균형 분할 방식 - 좌우 노드 수가 균등할 수 있게 반반 나뉘는 걸로 먼저 처리를.)\n",
        "* 이진 분류 -> 1, 0 => 몰아줄 수 있으면 먼저 처리를 해서 해당 노드는 더 이상 진행 X\n",
        "* 장점 : 빠르고, 성능 높게.\n",
        "* 단점 : 과최적화"
      ],
      "metadata": {
        "id": "6f8z_OngEqdp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 피쳐 엔지니어링 (특성 공학)\n",
        "* 피쳐 - 독립변수 - 관측값 - X\n",
        "* 어떠한 변수를 선택? 어떠한 변수 만듦? \n",
        "* 변수를 만들어서 영향?\n",
        "* 도메인 지식, 통계적으로. (z-점수, 차이값)\n",
        "* 행, 열을 가지고 조작하는 apply, 그룹을 만들어 연산 groupby, agg"
      ],
      "metadata": {
        "id": "cAyCYtPsEsNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 분류 평가 (classifier)\n",
        "## 정확도, 일치도 : accurany_score\n",
        "* (TP+TN) / (TP+FP+TN+NP)\n",
        "* 모델을 통해서 예측한 결과값 vs 실제 목표값 사이의 일치 여부\n",
        "* 0~1 사이의 일치 정도, 비율\n",
        "* 원래 99%로 한 쪽에 만약에 기울어있는 데이터면?\n",
        "* 점수는 높은데 뭔가 계속 놓쳐? vs 상대적으로 0.1점 낮은데... 균형있게 잘 분류해?\n",
        "\n",
        "## 혼동 행렬 (confusion matrix)\n",
        "\n",
        "|실제|예측|명칭|\n",
        "|-|-|-|\n",
        "|1|1|TP|\n",
        "|0|0|TN|\n",
        "|1|0|FN-위음성-2종 오류|\n",
        "|0|1|FP-위양성-1종 오류|\n",
        "\n",
        "## 분류 리포트 (classification report)\n",
        "* 정밀도 (precision) : TP / (TP+FP)\n",
        "    * 양성으로 분류한 것 중에서 진짜 양성은 얼마 정도인가?\n",
        "    * 위양성(잘못 양성으로 분류한 것)이 얼마나 적은가?\n",
        "* 재현율 (recall) : TP / (TP+FN)\n",
        "    * 실제 양성 중에 얼마나 양성으로 분류되었는가?\n",
        "    * 위음성(잘못 음성으로 분류한 것)이 얼마나 적은가?\n",
        "* F-1점수(f1-score)\n",
        "    * 정밀도와 재현율의 조화 평균\n",
        "    * 둘 다 신경써야할 때\n",
        "    \n",
        "$2 \\times \\frac{precision \\times recall}{precesion + recall}$\n",
        "=\n",
        "$2 \\times \\frac{정밀도 \\times 재현율}{정밀도 + 재현율}$\n",
        "\n",
        "`from skleran.metrics import classification_report`\n",
        "\n"
      ],
      "metadata": {
        "id": "hKMFGzRZEuEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 하이퍼 패러미터 튜닝\n",
        "* 학습율(learning rate) : 경사하강법을 쓸 때 얼마나 민감하게 (세세하게) 조정을 할 것이냐? -> 민감할 수록 오래걸리고, 과최적화. 둔감할 수록 학습 자체가 덜 될 가능성이 있음\n",
        "* 부분샘플(subsample) : 부트스트랩, 배깅.... -> 부분집합을 만들 때 얼마나 비율을 뽑아서 할 것이냐?\n",
        "* 그리드 서치 : 몇몇 대표적으로 쓰이는 설정값들을 다 조합을 넣어놓고, 하나하나 격자(조합)를 모델로 만들어서 평가 지표로 비교하는 기법\n",
        "    * 내가 모델을 하나씩 안 만들어봐도 가장 최고의 조합을 찾아줌\n",
        "    * cv(cross-validation/k-fold)까지하면 모델 수백개 만들어야함 -> 아무리 빨라도 몇 시간 걸림\n",
        "---\n",
        "* 피쳐 셀렉션\n",
        "    * `model.feature_importances_`\n",
        "    * 가장 많이 선택된 (영향을 미친) 변수들을 순서대로 \n",
        "    * 주요 변수만 선택해서, 다시 변수 추려내서 돌려볼 수 있음\n",
        "    * 주요 변수 -> 새로운 파생변수"
      ],
      "metadata": {
        "id": "THEPwrNWGG9g"
      }
    }
  ]
}