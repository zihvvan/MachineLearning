{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zihvvan/MachineLearning/blob/main/zihvvan/CH08_05%2B06_%EB%B3%B5%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 결정 트리 (Decision Tree, 의사결정)\n",
        "* 트리 cf) 그래프 (자료구조)\n",
        "    * 한 방향으로 전개되는 데이터 구조\n",
        "    * 뿌리(root)에서 잎(leaf)로 뻗어가면서 데이터가 갈라지는 구조\n",
        "    * 뿌리 하나에 가지(잎)이 2개 -> 이진 트리\n",
        "* 결정 트리 -> 이진 트리 -> 기준점(지니 계수 -> 특정한 변수의 값을 기준을 나누었을 때 결과값이 얼마나 순수하게 나뉘냐) (0, 1) => 특정 변수로 나누면... (0 그룹) (1그룹)으로 안 나뉘어짐\n",
        "    * 키 기준으로 남/녀를 나누었을 때랑, 운동화를 신었냐 기준으로 남녀를 나뉘었을 때? 어디가 좀 더 깔끔하게 남/녀 구분?\n",
        "* 전제가 없음\n",
        "    * 데이터의 선형성, 독립변수들 간의 다중공산성(상관성), 데이터의 이상치 여부, 데이터 단위 -> 신경써주지 않아도 됨\n",
        "    * 나눠지는 기준값을 기준으로 그룹을 나눠서 대응 -> 선형을 이루던가, 거리를 재던가 하지 않음, 그냥 반반 혹은 의미는 규모의 그룹으로 나누기\n",
        "    * 딥러닝을 제외한 머신러닝 쪽에서 가장 높은 예측력을 보이는 알고리즘 계열 -> 점점 고도화됨 -> 가장 기초적인 결정 트리 -> 경사하강법, 앙상블, 배깅, 부스팅 같은 기타 추가적인 기법들을 도입한 고도화된 트리 모델\n",
        "* 종속변수가 이산형이든 연속형이든 상관 없음, 분류문제/회귀문제 모두 대응 가능 (`classifier, regressor`)\n",
        "* 이걸 이해해야 뒤에 나오는 고도화된 트리 모델들의 기초 원리가 이해 가능\n",
        "* 가장 단순한 트리 모델이기 때문에, 시각화나 설명이 간단 (`plot_tree`)\n",
        "    * 예측력 (결과, 평가, 점수) vs 설명력 (시각화, 원인, 영향도) -> 자율주행, 내비게이션"
      ],
      "metadata": {
        "id": "nNL2FWcR6dQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 범주형 변수의 변환 -> 피쳐 엔지니어링적 성격\n",
        "* 순서형 : 크고 작음이 있다 -> A+ > B+ (학점), AAA > BBB (신용등급)\n",
        "    * 트리 계열 -> 라벨 인코딩 -> n개를 그냥 1~n까지로 인코딩해도 됨\n",
        "    * 범주형 변수 -> 거기에 대응하는 대표적인 값을 넣어서 순서형\n",
        "        * 나라 -> 나라별 고소득자 비율, 브랜드 -> 브랜드 평판, 해당 기업의 시가총액 (`groupby`, `merge`)\n",
        "        * 이렇게 변환해줄 경우에는 가능하면 안 겹치는 값\n",
        "        * 대표값을 잘못 적용해주면? 이상한 모델링\n",
        "* 명목형 : 위아래가 없음. 소속. 특성. 상태.\n",
        "    * 더미변수로 해줌\n",
        "---\n",
        "* 더미변수화를 하면, 해당 범주 종류(고윳값)의 n-1개의 행이 생김. (n-2개로 늘어남) -> 열이 늘어난 건, 행당 처리해야하는 데이터가 늘어남 -> 빅데이터(몇만, 몇십백만...) 배수로 늘어남 -> 100개의 종류가 있는 데이터 -> 더미변수화? -> 모델 학습 효율 떨어짐 -> 모델 성능의 문제, 효율"
      ],
      "metadata": {
        "id": "WWPfj2cpAon1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 결정 트리의 하이퍼 패러미터 튜닝\n",
        "* max_depth : 최대 노드의 깊이 -> 노드가 얼마나 밑으로 많이 전개되었는가? (최대)\n",
        "    * `from sklearn.tree import Decision...` -> default? : 확실히 두 그룹으로 나뉠 때까지\n",
        "    * 과최적화(오퍼피팅, over-fitting) : 훈련셋 데이터에 심하게 맞춰져 있어서, 새로운 데이터(검증셋,시험셋)을 만났을 때 제대로 분류\n",
        "    * 과소학습(언더피팅, under-fitting) : 학습이 제대로 안 됨\n",
        "    * 일정 이상 단계로 노드 전개(깊어지는 것)을 막아서, 너무 세세한 구분 조건을 주지 않게 함함"
      ],
      "metadata": {
        "id": "bFVGURLkDcbl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 랜덤 포레스트 (Random Forest)\n",
        "* 결정 트리 -> 과최적화 -> 앙상블(ensemble) -> 여러 모델들을 통합시켜서 더 좋은 예측력 보일 수 있게 하는 모델\n",
        "* 트리 -> 포레스트 -> 트리를 여러개 생성하고, 결과값들을 투표(분류 -> 모델1 : 0, 모델2: 0, 모델3: 1 -> 0)나 평균화 시켜서 예측력 높임\n",
        "* 이거 제외하건, 속도가 좀 느려진다(모델 여러개만들어서) 제외하곤 결정 트리하곤 유사. -> 여러개를 섞어서 시각화X"
      ],
      "metadata": {
        "id": "QVb98tn1Fb2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 단위 처리 & 도메인 지식을 이용한 전처리 (피쳐 엔지니어링)\n",
        "* 단위를 만나게 됨 -> cc, kg, N -> 숫자로 주어지는게 아니라, 단위와 함께(같은 열일 수도 있고, 다른 열 일수도 있지만...) 주어지는 경우 많음\n",
        "1. 값과 단위를 분리 (value, unit) -> `series.str.split()`, `series.str.split(expand=True)`, `series.str.extract(정규표현식)`, `series.apply(함수)`\n",
        "1. 단위가 한 가지인가?\n",
        "    1. 단위가 한 가지면 (cc, m 등으로 통일?) -> 그 값 자체를 써주면 됨\n",
        "    2. 단위가 두 가지 이상이면?\n",
        "        * 한쪽값으로 통일해주던가 (Nm, Kgm -> 변환공식이 존재할 경우)\n",
        "        * 가격, 석차, 비율.... -> 공통적? ex) 연료/연비 -> 가격/연비\n",
        "        * 도메인 지식 -> 특정 영역에 대해서 가지고 있는 상식, 기술적 지식."
      ],
      "metadata": {
        "id": "_0X4HQO4GuVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Fold\n",
        "* K가 등장한 것은? : 설정해주는 k값. k-fold는 데이터를 k구간만큼 나눠서 해당 `1~k번째`(`0~k-1번째`), 순서대로 시험셋으로 사용해줘서 `train_test_split`의 한계 -> 모델의 신뢰성, 평가에서 있어서의 정확도를 높임\n",
        "* 시간이 오래 걸림 k=5, 5등분 5번 모델. + 하이퍼패러미터 튜닝?"
      ],
      "metadata": {
        "id": "NbX_ttb6JG7f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 랜덤 포레스트의 하이퍼 패러미터 튜닝\n",
        "* n_estimators => 숲을 몇 개의 트리로 구성할 거임?\n",
        "---\n",
        "* 트리 기반에서 하이퍼 패러미터 튜닝은 주로 과소/과대적합 방지\n",
        "* max_depth\n",
        "* `min_samples_split` : 노드를 분할하기 위한 최소 샘플 수를 지정하는 매개변수입니다. 이 매개변수는 노드를 분할할 때, 해당 노드의 샘플 수가 min_samples_split보다 작아지면 분할을 멈추도록 합니다. 즉, 노드를 분할할 때 적어도 min_samples_split개 이상의 샘플이 있어야만 분할이 가능합니다. 이 값을 너무 낮게 설정하면 모델이 과적합(Overfitting)되기 쉽고, 너무 높게 설정하면 모델이 너무 단순해져서 과소적합(Underfitting)될 가능성이 높아집니다.\n",
        "* `min_samples_leaf` : 리프 노드가 되기 위한 최소 샘플 수를 지정하는 매개변수입니다. 이 매개변수는 리프 노드가 될 수 있는 샘플 수가 min_samples_leaf보다 작아지면 노드 분할을 멈추도록 합니다. 즉, 리프 노드가 될 수 있는 샘플 수가 min_samples_leaf보다 적다면 해당 노드는 분할을 멈추고 리프 노드가 됩니다. 이 값을 너무 낮게 설정하면 모델이 과적합되기 쉽고, 너무 높게 설정하면 모델이 너무 단순해져서 과소적합될 가능성이 높아집니다.\n",
        "\n",
        "차이점은 min_samples_split은 노드를 분할할 때 고려해야 할 최소 샘플 수를 설정하는 것이고, min_samples_leaf는 리프 노드가 되기 위한 최소 샘플 수를 설정하는 것입니다. min_samples_split은 노드 분할에 직접적으로 영향을 주며, min_samples_leaf는 리프 노드가 되기 위한 샘플 수를 조절하여 모델의 복잡도를 조절합니다. 따라서 두 매개변수 모두 모델의 복잡도를 조절하여 과적합과 과소적합을 방지하는 데 중요한 역할을 합니다."
      ],
      "metadata": {
        "id": "k11kx6NhJkbp"
      }
    }
  ]
}